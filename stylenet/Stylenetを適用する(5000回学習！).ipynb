{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stylenetは、2つの画像を使用し、1目の画像から画像スタイルを学習し、2爪の画像の内容に適用するという手法である。\n",
    "\n",
    "これが可能となるのは、画像の内容とは別に、スタイルと強い相関関係のある中間CNNノードが存在する場合である。\n",
    "（一部のCNNに2種類の中間層が存在するという特性）\n",
    "\n",
    "「画像のスタイルをエンコードするように見える中間層」と「画像の中身をエンコードするように見える中間層」\n",
    "\n",
    "これらを踏まえて、スタイル画像でスタイル層を、オリジナル画像で内容そうをトレーニングし、それらのトレーニングで計算された損失値をバックプロパゲートすれば、オリジナル画像をスタイル画像のような見た目に変更することができる。\n",
    "\n",
    "この処理を実現するには、論文で推奨されているimagenet-vgg-19というCNNを使う必要がある。\n",
    " http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat      \n",
    " \n",
    " \n",
    " オリジナル画像とスタイル画像の読み込み\n",
    " ↓\n",
    " トレーニング済みのCNNの重みを読み込んで、オリジナル画像とスタイル画像に層を割り当てる\n",
    " ↓\n",
    " オリジナル画像の損失値、スタイル画像の損失値、全変動損失値の３つの損失関数を計算\n",
    " ↓\n",
    " スタイル画像のスタイルとオリジナル画像の内容を組み合わせるために、ランダムノイズを使って画像のトレーニング\n",
    " ↓\n",
    " 画像の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#オリジナル画像とスタイル画像の場所を指定\n",
    "sess = tf.Session()\n",
    "\n",
    "#画像ファイル\n",
    "original_image_file = 'images/icu.jpeg'\n",
    "style_image_file = 'images/starry_night.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルのパラメーターとして、matファイルの場所、重み、学習率、イテレーション回数、中間画像を出力する頻度を設定\n",
    "#重みは、オリジナル画像に対してスタイル画像の非常を高くするのに役だ立つ\n",
    "vgg_path = 'imagenet-vgg-verydeep-19.mat'\n",
    "\n",
    "# Default Arguments\n",
    "original_image_weight = 5.0\n",
    "style_image_weight = 500.0\n",
    "regularization_weight = 100\n",
    "learning_rate = 0.001\n",
    "generations = 20\n",
    "output_generations = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#SciPyを使って２つの画像を読み込み、オリジナル画像の大きさに合わせてスタイル画像の形状を変更する\n",
    "#画像を読み込む\n",
    "original_image = scipy.misc.imread(original_image_file)\n",
    "style_image = scipy.misc.imread(style_image_file)\n",
    "\n",
    "#スタイル画像の形状をオリジナル画像と同じにする\n",
    "target_shape = original_image.shape\n",
    "style_image = scipy.misc.imresize(style_image, target_shape[1] / style_image.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#論文に基づき、層の順番を定義する（ここでは論文著者の命名規則を使用する）。\n",
    "# VGG-19 Layer Setup\n",
    "# From paper\n",
    "vgg_layers = ['conv1_1', 'relu1_1',\n",
    "              'conv1_2', 'relu1_2', 'pool1',\n",
    "              'conv2_1', 'relu2_1',\n",
    "              'conv2_2', 'relu2_2', 'pool2',\n",
    "              'conv3_1', 'relu3_1',\n",
    "              'conv3_2', 'relu3_2',\n",
    "              'conv3_3', 'relu3_3',\n",
    "              'conv3_4', 'relu3_4', 'pool3',\n",
    "              'conv4_1', 'relu4_1',\n",
    "              'conv4_2', 'relu4_2',\n",
    "              'conv4_3', 'relu4_3',\n",
    "              'conv4_4', 'relu4_4', 'pool4',\n",
    "              'conv5_1', 'relu5_1',\n",
    "              'conv5_2', 'relu5_2',\n",
    "              'conv5_3', 'relu5_3',\n",
    "              'conv5_4', 'relu5_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matファイルからパラメータを抽出する関数\n",
    "def extract_net_info(path_to_params):\n",
    "    vgg_data = scipy.io.loadmat(path_to_params)\n",
    "    normalization_matrix = vgg_data['normalization'][0][0][0]\n",
    "    mat_mean = np.mean(normalization_matrix, axis=(0,1))\n",
    "    network_weights = vgg_data['layers'][0]\n",
    "    return mat_mean, network_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抽出した重みと層の定義に基づき、TensorFlowでCNNを再現するための関数\n",
    "# 角層を順番に処理する際、適切な重みとバイアスを使用できるようにした上で、各層にあった関数を割り当てる\n",
    "# Create the VGG-19 Network\n",
    "def vgg_network(network_weights, init_image):\n",
    "    network = {}\n",
    "    image = init_image\n",
    "\n",
    "    for i, layer in enumerate(vgg_layers):\n",
    "        if layer[0] == 'c':\n",
    "            weights, bias = network_weights[i][0][0][0][0]\n",
    "            weights = np.transpose(weights, (1, 0, 2, 3))\n",
    "            bias = bias.reshape(-1)\n",
    "            conv_layer = tf.nn.conv2d(image, tf.constant(weights), (1, 1, 1, 1), 'SAME')\n",
    "            image = tf.nn.bias_add(conv_layer, bias)\n",
    "        elif layer[0] == 'r':\n",
    "            image = tf.nn.relu(image)\n",
    "        else:  # pooling\n",
    "            image = tf.nn.max_pool(image, (1, 2, 2, 1), (1, 2, 2, 1), 'SAME')\n",
    "        network[layer] = image\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# どの層を適応させるか選択（オリジナル画像はrelu4_2のまま、スタイル画像はrelu_X層の出力を組み合わせてみる）\n",
    "original_layer = 'relu4_2'\n",
    "style_layers = ['relu1_1', 'relu2_1', 'relu3_1', 'relu4_1', 'relu5_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_net()を実行して重みと平均を取得する。\n",
    "# TensorFlowの画像演算は4つの次元を操作するため、先頭にサイズ１の次元を追加し画像の行列の形状を変更する。\n",
    "normalization_mean, network_weights = extract_net_info(vgg_path)\n",
    "\n",
    "shape = (1,) + original_image.shape\n",
    "style_shape = (1,) + style_image.shape\n",
    "original_features = {}\n",
    "style_features = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageプレースホルダを設定し、このプレースホルダを使ってネットワークを形成する\n",
    "image = tf.placeholder('float', shape=shape)\n",
    "vgg_net = vgg_network(network_weights, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オリジナル画像の行列を正規化し、ネットワークを通じて実行する\n",
    "original_minus_mean = original_image - normalization_mean\n",
    "original_norm = np.array([original_minus_mean])\n",
    "original_features[original_layer] = sess.run(vgg_net[original_layer], feed_dict= {image: original_norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選択したスタイル画像の層ごとに同じ処理を繰り返す\n",
    "image = tf.placeholder('float', shape=style_shape)\n",
    "vgg_net = vgg_network(network_weights, image)\n",
    "style_minus_mean = style_image - normalization_mean\n",
    "style_norm = np.array([style_minus_mean])\n",
    "\n",
    "for layer in style_layers:\n",
    "    layer_output = sess.run(vgg_net[layer], feed_dict={image: style_norm})\n",
    "    layer_output = np.reshape(layer_output, (-1, layer_output.shape[3]))\n",
    "    style_gram_matrix = np.matmul(layer_output.T, layer_output) / layer_output.size\n",
    "    style_features[layer] = style_gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オリジナル画像とスタイル画像を組み合わせる処理は、ランダムノイズを適用した上でネットワークで実行する\n",
    "initial = tf.random_normal(shape) * 0.256\n",
    "image = tf.Variable(initial)\n",
    "vgg_net = vgg_network(network_weights, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の損失値としてオリジナル画像の損失値を設定する\n",
    "# ここでは正規化されたオリジナル画像の出力と、オリジナル画像の内容を表すために指定された層の出力との間で、サイズが正規化されたL2損失値を計算する\n",
    "original_loss = original_image_weight * (2 * tf.nn.l2_loss(\n",
    "    vgg_net[original_layer] - original_features[original_layer]) /\n",
    "    original_features[original_layer].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2つ目の損失値としてスタイル画像の層ごとに同じ種類の損失値を計算し、それぞれの値を加算していく\n",
    "style_loss = 0\n",
    "style_losses = []\n",
    "for style_layer in style_layers:\n",
    "    layer = vgg_net[style_layer]\n",
    "    feats, height, width, channels = [x.value for x in layer.get_shape()]\n",
    "    size = height * width * channels\n",
    "    features = tf.reshape(layer, (-1, channels))\n",
    "    style_gram_matrix = tf.matmul(tf.transpose(features), features) / size\n",
    "    style_expected = style_features[style_layer]\n",
    "    style_losses.append(\n",
    "        2 * tf.nn.l2_loss(style_gram_matrix - style_expected) / style_expected.size)\n",
    "style_loss += style_image_weight * tf.reduce_sum(style_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3つ目の損失値は全変動損失と呼ばれるもので、全変動を計算することによって得られる。\n",
    "# ノイズの近くにあるピクセルを取り除き（second_term_numerator）画像の特異値を最小化対象の損失関数として扱う\n",
    "# 滑らかな結果を得るために全変動損失を追加\n",
    "total_var_x = sess.run(tf.reduce_prod(image[:, 1:, :, :].get_shape()))\n",
    "total_var_y = sess.run(tf.reduce_prod(image[:, :, 1:, :].get_shape()))\n",
    "first_term = regularization_weight * 2\n",
    "second_term_numerator = tf.nn.l2_loss(image[:, 1:, :, :] - image[:, :shape[1]-1, :, :])\n",
    "second_term = second_term_numerator / total_var_y\n",
    "third_term = (tf.nn.l2_loss(image[:, :, 1:, :] - image[:, :, :shape[2]-1, :]) / total_var_x)\n",
    "total_variation_loss = first_term * (second_term + third_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失値を組み合わせる\n",
    "loss = original_loss + style_loss + total_variation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化関数とトレーニングステップを設定し、モデルのすべての変数を初期化する\n",
    "# 最適化関数を設定\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# 変数を初期化し、トレーニンングを開始\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 out of 20, loss: 338176928.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 10 out of 20, loss: 338165696.0\n",
      "Generation 15 out of 20, loss: 338154080.0\n",
      "Generation 20 out of 20, loss: 338142208.0\n"
     ]
    }
   ],
   "source": [
    "# トレーニングループを開始\n",
    "# 定期的的に生成された画像を保存（選択した画像に応じて異なる可能性があるため、満足のいく画像が出力された時にアルゴリズムの実行を中止する）\n",
    "for i in range(generations):\n",
    "    sess.run(train_step)\n",
    "    # Print update and save temporary output\n",
    "    if (i+1) % output_generations == 0:\n",
    "        print('Generation {} out of {}, loss: {}'.format(i + 1, generations,sess.run(loss)))\n",
    "        image_eval = sess.run(image)\n",
    "        best_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "        output_file = 'temp_output_{}.jpg'.format(i)\n",
    "        scipy.misc.imsave(output_file, best_image_add_mean)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# 最終的な出力を保存する\n",
    "image_eval = sess.run(image)\n",
    "best_image_add_mean = image_eval.reshape(shape[1:]) + normalization_mean\n",
    "output_file = 'final_output.jpg'\n",
    "scipy.misc.imsave(output_file, best_image_add_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
